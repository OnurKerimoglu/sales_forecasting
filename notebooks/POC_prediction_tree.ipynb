{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline: Tree-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import parquet\n",
    "\n",
    "from tree_predictor import TreePredictor\n",
    "from utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Utils.read_config_for_env(config_path='../config/config.yml')\n",
    "treepredictor = TreePredictor(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_data(df_daily, df_shops, df_items, splitname, refresh):\n",
    "    fn_base = os.path.join(config['root_data_path'], config[f'fn_{splitname}_base'])\n",
    "    if os.path.exists(fn_base) and not refresh:\n",
    "        print(f'Loading {fn_base}')\n",
    "        df_base = pd.read_parquet(fn_base)\n",
    "    else:\n",
    "        print(f'Creating {fn_base}')\n",
    "        df_base = prep_monthly_data(df_daily, df_shops, df_items)\n",
    "        df_base.to_parquet(fn_base)\n",
    "    return df_base\n",
    "\n",
    "def prep_monthly_data(df_daily, df_shops, df_items):\n",
    "    # Create a full Item-Amounts table\n",
    "    df_items_monthly = create_items_df_monthly(df_daily, df_shops, df_items) \n",
    "    # Add missing category_id's\n",
    "    df_items_monthly = add_category_to_df(df_items_monthly, df_items)\n",
    "    # df_items_monthly.info()\n",
    "    # Add missing prices of non-transacted items: first based on average price of items in each shop, then average price of items in all shops, then average price of categories in all shops, then the global average price.\n",
    "    df_items_monthly = add_avg_shopitem_price_to_df(df_items_monthly, df_daily, 'mean shop-item-specific price')\n",
    "    # df_items_monthly.info()\n",
    "    # Add category amounts as a feature\n",
    "    # Create a full Item-Amounts table\n",
    "    df_categories_monthly = create_categories_df_monthly(df_daily, df_shops, df_items)\n",
    "    # Merge the items and categories tables\n",
    "    df_monthly = pd.merge(\n",
    "        df_items_monthly,\n",
    "        df_categories_monthly,\n",
    "        how='left',\n",
    "        on=['shop_id', 'item_category_id', 'monthly_period'],\n",
    "        suffixes=('_item', '_cat'))\n",
    "    # df_monthly.info(show_counts=True)\n",
    "    # add time features\n",
    "    df_monthly = add_time_features(df_monthly)\n",
    "    # set monthly_period as index\n",
    "    df_monthly.set_index('monthly_period', inplace=True)\n",
    "    return df_monthly\n",
    "\n",
    "def create_items_df_monthly(df_daily, df_shops, df_items):\n",
    "    df_items_monthly_transactions = convert_items_daily_to_monthly(\n",
    "        df_daily\n",
    "    )\n",
    "    # df_items_monthly_transactions.info()\n",
    "    columns = ['shop_id', 'item_id', 'monthly_period']\n",
    "    df_items_monthly_all = create_df_all(\n",
    "        columns=columns,\n",
    "        shops=df_shops['shop_id'].unique(),\n",
    "        items=df_items['item_id'].unique(),\n",
    "        dates=df_items_monthly_transactions['monthly_period'].unique()\n",
    "    )\n",
    "    # df_items_monthly_all.info()\n",
    "    df_items_monthly = create_df_with_zero_sales(\n",
    "        df_items_monthly_transactions,\n",
    "        df_items_monthly_all,\n",
    "        columns)\n",
    "    # df_items_monthly.info()\n",
    "    return df_items_monthly\n",
    "\n",
    "def convert_items_daily_to_monthly(df):\n",
    "    df_items_monthly_grouped = df.groupby(\n",
    "    ['shop_id', 'item_id', 'monthly_period']\n",
    "    )\n",
    "    df_items_monthly = df_items_monthly_grouped.agg(\n",
    "        {\n",
    "        'item_category_id': 'first',\n",
    "        'price': 'mean',\n",
    "        'amount': 'sum',\n",
    "        }\n",
    "    ).reset_index()\n",
    "    return df_items_monthly\n",
    "\n",
    "def create_df_all(columns, shops, items, dates):\n",
    "    # Generate all possible combinations of shops, items, and dates.\n",
    "    all_combinations = list(itertools.product(shops, items, dates))\n",
    "    df_all = pd.DataFrame(all_combinations, columns=columns)\n",
    "    return df_all\n",
    "\n",
    "def create_df_all_limited(df, coldict):\n",
    "    shop_item_pairs = df[[coldict['shops'], coldict['items']]].drop_duplicates()\n",
    "\n",
    "    dates = df[coldict['date']].unique()\n",
    "\n",
    "    # Create a list of all possible combinations of shop-item pairs with the dates\n",
    "    df_all = pd.DataFrame(\n",
    "        list(itertools.product(shop_item_pairs.values, dates)),\n",
    "        columns=['shop_item', coldict['date']])\n",
    "    # Split the 'shop_item' column back into separate 'shop_id' and 'item_id' columns\n",
    "    df_all[[coldict['shops'], coldict['items']]] = pd.DataFrame(\n",
    "        df_all['shop_item'].tolist(), \n",
    "        index=df_all.index)\n",
    "    # Drop the intermediate 'shop_item' column\n",
    "    df_all = df_all.drop(columns=['shop_item'])\n",
    "    return df_all\n",
    "\n",
    "def create_df_with_zero_sales(df, df_all, columns):\n",
    "    # Merge with the original dataframe\n",
    "    df_merged = pd.merge(\n",
    "        df_all,\n",
    "        df,\n",
    "        on=columns,\n",
    "        how='left')\n",
    "    # Fill missing values with 0\n",
    "    # df_merged['amount'].fillna(0, inplace=True)\n",
    "    df_merged.fillna({'amount': 0}, inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "def create_categories_df_monthly(df_daily, df_shops, df_items):\n",
    "    df_categories_monthly_transactions = convert_categories_daily_to_monthly(\n",
    "        df_daily\n",
    "    )\n",
    "    # df_categories_monthly_transactions.info()\n",
    "    columns = ['shop_id', 'item_category_id', 'monthly_period']\n",
    "    df_categories_monthly_all = create_df_all(\n",
    "        columns=columns,\n",
    "        shops=df_shops['shop_id'].unique(),\n",
    "        items=df_items['item_category_id'].unique(),\n",
    "        dates=df_categories_monthly_transactions['monthly_period'].unique()\n",
    "    )\n",
    "    # df_categories_monthly_all.info()\n",
    "    df_categories_monthly = create_df_with_zero_sales(\n",
    "        df_categories_monthly_transactions,\n",
    "        df_categories_monthly_all,\n",
    "        columns)\n",
    "    #df_categories_monthly.info()\n",
    "    return df_categories_monthly\n",
    "\n",
    "def convert_categories_daily_to_monthly(df):\n",
    "    df_categories_monthly_grouped = df.groupby(\n",
    "    ['shop_id', 'item_category_id', 'monthly_period']\n",
    "    )\n",
    "    df_categories_monthly = df_categories_monthly_grouped.agg(\n",
    "        {\n",
    "        'amount': 'sum',\n",
    "        }\n",
    "    ).reset_index()\n",
    "    return df_categories_monthly\n",
    "\n",
    "def add_category_to_df(df_monthly, df_items):\n",
    "    df_monthly_full = df_monthly.loc[df_monthly['item_category_id'].notna(), :]  #.copy()\n",
    "    df_monthly_missing = df_monthly.loc[df_monthly['item_category_id'].isna(), :].copy()\n",
    "    df_monthly_missing.drop(['item_category_id'], axis=1, inplace=True)\n",
    "    df_monthly_missing_filled = pd.merge(\n",
    "        df_monthly_missing,\n",
    "        df_items,\n",
    "        on='item_id',\n",
    "        how='left')\n",
    "    df_items_monthly = pd.concat([df_monthly_full, df_monthly_missing_filled], ignore_index=True)\n",
    "    df_items_monthly = df_items_monthly.sort_values(by = ['monthly_period', 'shop_id', 'item_id'])\n",
    "    count_missing_cats = df_items_monthly.loc[df_items_monthly['item_category_id'].isna(), :].shape[0]\n",
    "    print(f'after the operation, count of rows with missing categories: {count_missing_cats}')\n",
    "    return df_items_monthly\n",
    "\n",
    "def add_avg_shopitem_price_to_df(df_monthly, df_daily_train, method):\n",
    "    df_monthly_full = df_monthly.loc[df_monthly['price'].notna(), :]\n",
    "    df_monthly_miss = df_monthly.loc[df_monthly['price'].isna(), :].copy()\n",
    "    print(f'{df_monthly_full.shape[0]} and {df_monthly_miss.shape[0]} rows with filled and missing prices, respectively.')\n",
    "    if df_monthly_miss.shape[0] > 0:\n",
    "        print(f'Filling missing with {method}')\n",
    "        df_monthly_miss.drop(['price'], axis=1, inplace=True)\n",
    "        mean_price, merge_columns = get_mean_price(df_daily_train, method)\n",
    "        # fill the missing\n",
    "        df_monthly_miss_filled = pd.merge(\n",
    "            df_monthly_miss, \n",
    "            mean_price,\n",
    "            on=merge_columns,\n",
    "            how='left')\n",
    "        df_monthly = pd.concat([df_monthly_full, df_monthly_miss_filled], ignore_index=True)\n",
    "        df_monthly = df_monthly.sort_values(by = ['monthly_period', 'shop_id', 'item_id'])\n",
    "        count_missing_price = df_monthly.loc[df_monthly['price'].isna(), :].shape[0]\n",
    "        print(f'after the operation, count of rows with missing price: {count_missing_price}')\n",
    "        if count_missing_price > 0: \n",
    "            if method == 'mean shop-item-specific price':\n",
    "                df_monthly = add_avg_shopitem_price_to_df(df_monthly, df_daily_train, 'mean item-specific price')\n",
    "            elif method == 'mean item-specific price':\n",
    "                df_monthly = add_avg_shopitem_price_to_df(df_monthly, df_daily_train, 'mean category-specific price')\n",
    "            elif method == 'mean category-specific price':\n",
    "                print(f'Filling missing with global average price')\n",
    "                global_avg_price = df_daily_train[['price']].mean().values[0]\n",
    "                df_monthly.loc[df_monthly['price'].isna(), 'price'] = float(global_avg_price)\n",
    "            else:\n",
    "                raise ValueError(f'Uknown method: {method}')\n",
    "    else:\n",
    "        df_monthly = df_monthly_full\n",
    "    return df_monthly\n",
    "\n",
    "def get_mean_price(df_daily_train, method):\n",
    "    if method == 'mean shop-item-specific price':\n",
    "        # calculate mean shop-item price:\n",
    "        mean_price = df_daily_train[['shop_id', 'item_id', 'price']].groupby(['shop_id', 'item_id']).mean().reset_index()\n",
    "        merge_columns = ['shop_id', 'item_id']\n",
    "    elif method == 'mean item-specific price':\n",
    "        mean_price = df_daily_train[['item_id', 'price']].groupby(['item_id']).mean().reset_index()\n",
    "        merge_columns = ['item_id']\n",
    "    elif method == 'mean category-specific price':\n",
    "        mean_price = df_daily_train[['item_category_id', 'price']].groupby(['item_category_id']).mean().reset_index()\n",
    "        merge_columns = ['item_category_id']\n",
    "    else:\n",
    "        raise ValueError(f'Uknown method: {method}')\n",
    "    return mean_price, merge_columns\n",
    "\n",
    "# Year and month can help capturing the trend and the seasonality, respectively\n",
    "def add_time_features(df_monthly):\n",
    "    df_monthly['year'] = df_monthly['monthly_period'].dt.year\n",
    "    df_monthly['month'] = df_monthly['monthly_period'].dt.month\n",
    "    return df_monthly\n",
    "\n",
    "def get_ts_data(df_base, splitname, refresh):\n",
    "    fn_ts = os.path.join(config['root_data_path'], config[f'fn_{splitname}_ts'])\n",
    "    if os.path.exists(fn_ts) and not refresh:\n",
    "        print(f'Loading {fn_ts}')\n",
    "        df_ts = pd.read_parquet(fn_ts)\n",
    "    else:\n",
    "        print(f'Creating {fn_ts}')\n",
    "        df_ts = add_lag_ma_features(\n",
    "            df_base,\n",
    "            lags_to_include = treepredictor.num_lag_mon)\n",
    "        # remove the months for which lags could not be calculated\n",
    "        periods_to_remove = df_ts.index.unique()[0:treepredictor.num_lag_mon]\n",
    "        df_ts = df_ts.drop(periods_to_remove)\n",
    "        df_ts.to_parquet(fn_ts)\n",
    "    return df_ts\n",
    "\n",
    "def add_lag_ma_features(\n",
    "        df_monthly,\n",
    "        lags_to_include=3,\n",
    "        lag_features=['price', 'amount_item', 'amount_cat'],\n",
    "        mas_to_include=[2],\n",
    "        ma_features=['price_l1', 'amount_item_l1', 'amount_cat_l1']\n",
    "        ):\n",
    "    for feature in lag_features:\n",
    "        df_monthly = add_feature_lags(\n",
    "            df_monthly,\n",
    "            feature,\n",
    "            lags_to_include)\n",
    "    for feature in ma_features:\n",
    "        df_monthly = add_feature_moving_averages(\n",
    "            df_monthly,\n",
    "            feature,\n",
    "            mas_to_include)\n",
    "    return df_monthly\n",
    "\n",
    "def add_feature_lags(df, column, lagcount):\n",
    "    for lag in range(1, lagcount+1):\n",
    "        new_column_name = column + '_l' + str(lag)\n",
    "        df[new_column_name] = df.groupby(['shop_id', 'item_id'])[column].shift(lag)\n",
    "    return df\n",
    "\n",
    "def add_feature_moving_averages(df, column, windows):\n",
    "    for window in windows:\n",
    "        new_column_name = column + '_ma' + str(window)\n",
    "        df[new_column_name] = df.groupby(['shop_id', 'item_id'])[column].transform(lambda x: x.rolling(window=window).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare monthly training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data needed for both train and val\n",
    "df_shops= treepredictor.rawdata.shop_list\n",
    "df_items = treepredictor.rawdata.item_list[['item_id', 'item_category_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_pipeline(\n",
    "        df_daily,\n",
    "        df_shops,\n",
    "        df_items,\n",
    "        splitname,\n",
    "        refresh):\n",
    "    \n",
    "    # get base monthly data\n",
    "    df_base = get_monthly_data(df_daily, df_shops, df_items, splitname, refresh)\n",
    "\n",
    "    # get monthly data with lag and ma features\n",
    "    df_ts= get_ts_data(df_base, splitname, refresh)\n",
    "    \n",
    "    # TODO: scaling\n",
    "\n",
    "    # TODO: OHE\n",
    "\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = ['monthly_period', 'shop_id', 'item_id', 'item_category_id', 'amount', 'price']\n",
    "df_daily_train = treepredictor.df_daily_train[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_train = data_prep_pipeline(\n",
    "    df_daily_train,\n",
    "    df_shops,\n",
    "    df_items,\n",
    "    'train',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "train_y = df_train['amount_item']\n",
    "df_train.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "train_X = df_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_val = treepredictor.df_daily_val[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_val = data_prep_pipeline(\n",
    "    df_daily_val,\n",
    "    df_shops,\n",
    "    df_items,\n",
    "    'val',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "val_y = df_val['amount_item']\n",
    "df_val.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "val_X = df_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
