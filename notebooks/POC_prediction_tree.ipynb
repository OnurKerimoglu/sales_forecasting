{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline: Tree-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictor import BasePredictor\n",
    "from utils import Utils\n",
    "\n",
    "config = Utils.read_config_for_env(config_path='../config/config.yml')\n",
    "predictor = BasePredictor(\n",
    "    config,\n",
    "    refresh_monthly=False,\n",
    "    refresh_ts_features=False,\n",
    "    clean_strategy='olrem_for_all',\n",
    "    split_strategy='random',\n",
    "    num_lag_mon=3,\n",
    "    val_ratio=0.2,\n",
    "    scaler_type='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data and do the scaling:\n",
    "# stores X_train, y_train, X_val, y_val and feature_names in predictor object\n",
    "predictor.split_scale_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# from lightgbm import LGBMRegressor \n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error as mse \n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LightGBM dataset for training with features X_train and labels Y_train \n",
    "train_data = lgb.Dataset(\n",
    "    predictor.X_train,\n",
    "    label=predictor.y_train,\n",
    "    feature_name=predictor.feature_names) \n",
    "# Create a LightGBM dataset for testing with features X_val and labels Y_val, \n",
    "# and specify the reference dataset as train_data for consistent evaluation \n",
    "val_data = lgb.Dataset(\n",
    "    predictor.X_val,\n",
    "    label=predictor.y_val,\n",
    "    feature_name=predictor.feature_names,\n",
    "    reference=train_data) \n",
    "# Define a dictionary of parameters for configuring the LightGBM regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "}\n",
    "callback_early_stopping = lgb.early_stopping(5)\n",
    "num_round = 100\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_round,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[callback_early_stopping, lgb.log_evaluation()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and validation data. \n",
    "pred_train = model.predict(predictor.X_train)\n",
    "pred_val = model.predict(predictor.X_val)\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE) for training and validation predictions. \n",
    "print(\"Training RMSE: \", np.sqrt(mse(predictor.y_train, pred_train)))\n",
    "print(\"Validation RMSE: \", np.sqrt(mse(predictor.y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM tuned with AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 600,  # total running time in seconds\n",
    "    \"metric\": \"mse\",  # primary metrics for regression can be chosen from: ['mae','mse','r2']\n",
    "    \"estimator_list\": [\"lgbm\"],  # list of ML learners; we tune lightgbm in this example\n",
    "    \"task\": \"regression\",  # task type\n",
    "    \"log_file_name\": \"store_sales_lgbm.log\"  # flaml log file\n",
    "    # \"seed\": 42,  # random seed\n",
    "}\n",
    "automl.fit(\n",
    "    X_train=predictor.X_train,\n",
    "    y_train=predictor.y_train,\n",
    "    **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.automl.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = get_output_from_log(filename=settings['log_file_name'], time_budget=600)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation r2')\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparmeter config:\", automl.best_config)\n",
    "print(\"Best r2 on validation data: {0:.4g}\".format(1 - automl.best_loss))\n",
    "print(\"Training duration of best run: {0:.4g} s\".format(automl.best_config_train_time))\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and validation data. \n",
    "pred_train = automl.predict(predictor.X_train)\n",
    "pred_val = automl.predict(predictor.X_val)\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE) for training and validation predictions. \n",
    "print(\"Training RMSE: \", np.sqrt(mse(predictor.y_train, pred_train)))\n",
    "print(\"Validation RMSE: \", np.sqrt(mse(predictor.y_val, pred_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.barh(automl.feature_names_in_, automl.feature_importances_)\n",
    "plt.barh(predictor.feature_names, automl.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = np.arange(20).reshape((5, 4))\n",
    "X.shape\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
