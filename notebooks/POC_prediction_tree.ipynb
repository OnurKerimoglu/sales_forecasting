{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline: Tree-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import parquet\n",
    "\n",
    "from tree_predictor import TreePredictor\n",
    "from utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.. Done.\n",
      "Fixing data schemas.. Done.\n",
      "Cleaning training data\n",
      "Checking for negative values in ['price', 'amount'].. Count of rows marked as invalid: 6469\n",
      "Checking for outliers in ['price', 'amount'].. Count of rows marked as invalid: 40138\n",
      "Count of cleaned rows: 46248\n",
      "Cleaning validation data\n",
      "Checking for negative values in ['price', 'amount'].. Count of rows marked as invalid: 760\n",
      "Count of cleaned rows: 760\n",
      "Prepared daily raw data.\n"
     ]
    }
   ],
   "source": [
    "config = Utils.read_config_for_env(config_path='../config/config.yml')\n",
    "treepredictor = TreePredictor(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_monthly_data(df_daily, df_shops, df_items):\n",
    "    # Create a full Item-Amounts table\n",
    "    df_items_monthly = create_items_df_monthly(df_daily, df_shops, df_items) \n",
    "    # Add missing category_id's\n",
    "    df_items_monthly = add_category_to_df(df_items_monthly, df_items)\n",
    "    # df_items_monthly.info()\n",
    "    # Add missing prices of non-transacted items: first based on average price of items in each shop, then average price of items in all shops, then average price of categories in all shops, then the global average price.\n",
    "    df_items_monthly = add_avg_shopitem_price_to_df(df_items_monthly, df_daily, 'mean shop-item-specific price')\n",
    "    # df_items_monthly.info()\n",
    "    # Add category amounts as a feature\n",
    "    # Create a full Item-Amounts table\n",
    "    df_categories_monthly = create_categories_df_monthly(df_daily, df_shops, df_items)\n",
    "    # Merge the items and categories tables\n",
    "    df_monthly = pd.merge(\n",
    "        df_items_monthly,\n",
    "        df_categories_monthly,\n",
    "        how='left',\n",
    "        on=['shop_id', 'item_category_id', 'monthly_period'],\n",
    "        suffixes=('_item', '_cat'))\n",
    "    # df_monthly.info(show_counts=True)\n",
    "    # add time features\n",
    "    df_monthly = add_time_features(df_monthly)\n",
    "    # set monthly_period as index\n",
    "    df_monthly.set_index('monthly_period', inplace=True)\n",
    "    return df_monthly\n",
    "\n",
    "def create_items_df_monthly(df_daily, df_shops, df_items):\n",
    "    df_items_monthly_transactions = convert_items_daily_to_monthly(\n",
    "        df_daily\n",
    "    )\n",
    "    # df_items_monthly_transactions.info()\n",
    "    columns = ['shop_id', 'item_id', 'monthly_period']\n",
    "    df_items_monthly_all = create_df_all(\n",
    "        columns=columns,\n",
    "        shops=df_shops['shop_id'].unique(),\n",
    "        items=df_items['item_id'].unique(),\n",
    "        dates=df_items_monthly_transactions['monthly_period'].unique()\n",
    "    )\n",
    "    # df_items_monthly_all.info()\n",
    "    df_items_monthly = create_df_with_zero_sales(\n",
    "        df_items_monthly_transactions,\n",
    "        df_items_monthly_all,\n",
    "        columns)\n",
    "    # df_items_monthly.info()\n",
    "    return df_items_monthly\n",
    "\n",
    "def create_categories_df_monthly(df_daily, df_shops, df_items):\n",
    "    df_categories_monthly_transactions = convert_categories_daily_to_monthly(\n",
    "        df_daily\n",
    "    )\n",
    "    # df_categories_monthly_transactions.info()\n",
    "    columns = ['shop_id', 'item_category_id', 'monthly_period']\n",
    "    df_categories_monthly_all = create_df_all(\n",
    "        columns=columns,\n",
    "        shops=df_shops['shop_id'].unique(),\n",
    "        items=df_items['item_category_id'].unique(),\n",
    "        dates=df_categories_monthly_transactions['monthly_period'].unique()\n",
    "    )\n",
    "    # df_categories_monthly_all.info()\n",
    "    df_categories_monthly = create_df_with_zero_sales(\n",
    "        df_categories_monthly_transactions,\n",
    "        df_categories_monthly_all,\n",
    "        columns)\n",
    "    #df_categories_monthly.info()\n",
    "    return df_categories_monthly\n",
    "\n",
    "def create_df_all(columns, shops, items, dates):\n",
    "    # Generate all possible combinations of shops, items, and dates.\n",
    "    all_combinations = list(itertools.product(shops, items, dates))\n",
    "    df_all = pd.DataFrame(all_combinations, columns=columns)\n",
    "    return df_all\n",
    "\n",
    "def create_df_all_limited(df, coldict):\n",
    "    shop_item_pairs = df[[coldict['shops'], coldict['items']]].drop_duplicates()\n",
    "\n",
    "    dates = df[coldict['date']].unique()\n",
    "\n",
    "    # Create a list of all possible combinations of shop-item pairs with the dates\n",
    "    df_all = pd.DataFrame(\n",
    "        list(itertools.product(shop_item_pairs.values, dates)),\n",
    "        columns=['shop_item', coldict['date']])\n",
    "    # Split the 'shop_item' column back into separate 'shop_id' and 'item_id' columns\n",
    "    df_all[[coldict['shops'], coldict['items']]] = pd.DataFrame(\n",
    "        df_all['shop_item'].tolist(), \n",
    "        index=df_all.index)\n",
    "    # Drop the intermediate 'shop_item' column\n",
    "    df_all = df_all.drop(columns=['shop_item'])\n",
    "    return df_all\n",
    "\n",
    "def create_df_with_zero_sales(df, df_all, columns):\n",
    "    # Merge with the original dataframe\n",
    "    df_merged = pd.merge(\n",
    "        df_all,\n",
    "        df,\n",
    "        on=columns,\n",
    "        how='left')\n",
    "    # Fill missing values with 0\n",
    "    # df_merged['amount'].fillna(0, inplace=True)\n",
    "    df_merged.fillna({'amount': 0}, inplace=True)\n",
    "    return df_merged\n",
    "\n",
    "def convert_items_daily_to_monthly(df):\n",
    "    df_items_monthly_grouped = df.groupby(\n",
    "    ['shop_id', 'item_id', 'monthly_period']\n",
    "    )\n",
    "    df_items_monthly = df_items_monthly_grouped.agg(\n",
    "        {\n",
    "        'item_category_id': 'first',\n",
    "        'price': 'mean',\n",
    "        'amount': 'sum',\n",
    "        }\n",
    "    ).reset_index()\n",
    "    return df_items_monthly\n",
    "\n",
    "def convert_categories_daily_to_monthly(df):\n",
    "    df_categories_monthly_grouped = df.groupby(\n",
    "    ['shop_id', 'item_category_id', 'monthly_period']\n",
    "    )\n",
    "    df_categories_monthly = df_categories_monthly_grouped.agg(\n",
    "        {\n",
    "        'amount': 'sum',\n",
    "        }\n",
    "    ).reset_index()\n",
    "    return df_categories_monthly\n",
    "\n",
    "def add_category_to_df(df_monthly, df_items):\n",
    "    df_monthly_full = df_monthly.loc[df_monthly['item_category_id'].notna(), :]  #.copy()\n",
    "    df_monthly_missing = df_monthly.loc[df_monthly['item_category_id'].isna(), :].copy()\n",
    "    df_monthly_missing.drop(['item_category_id'], axis=1, inplace=True)\n",
    "    df_monthly_missing_filled = pd.merge(\n",
    "        df_monthly_missing,\n",
    "        df_items,\n",
    "        on='item_id',\n",
    "        how='left')\n",
    "    df_items_monthly = pd.concat([df_monthly_full, df_monthly_missing_filled], ignore_index=True)\n",
    "    df_items_monthly = df_items_monthly.sort_values(by = ['monthly_period', 'shop_id', 'item_id'])\n",
    "    count_missing_cats = df_items_monthly.loc[df_items_monthly['item_category_id'].isna(), :].shape[0]\n",
    "    print(f'after the operation, count of rows with missing categories: {count_missing_cats}')\n",
    "    return df_items_monthly\n",
    "\n",
    "def get_mean_price(df_daily_train, method):\n",
    "    if method == 'mean shop-item-specific price':\n",
    "        # calculate mean shop-item price:\n",
    "        mean_price = df_daily_train[['shop_id', 'item_id', 'price']].groupby(['shop_id', 'item_id']).mean().reset_index()\n",
    "        merge_columns = ['shop_id', 'item_id']\n",
    "    elif method == 'mean item-specific price':\n",
    "        mean_price = df_daily_train[['item_id', 'price']].groupby(['item_id']).mean().reset_index()\n",
    "        merge_columns = ['item_id']\n",
    "    elif method == 'mean category-specific price':\n",
    "        mean_price = df_daily_train[['item_category_id', 'price']].groupby(['item_category_id']).mean().reset_index()\n",
    "        merge_columns = ['item_category_id']\n",
    "    else:\n",
    "        raise ValueError(f'Uknown method: {method}')\n",
    "    return mean_price, merge_columns\n",
    "\n",
    "def add_avg_shopitem_price_to_df(df_monthly, df_daily_train, method):\n",
    "    df_monthly_full = df_monthly.loc[df_monthly['price'].notna(), :]\n",
    "    df_monthly_miss = df_monthly.loc[df_monthly['price'].isna(), :].copy()\n",
    "    print(f'{df_monthly_full.shape[0]} and {df_monthly_miss.shape[0]} rows with filled and missing prices, respectively.')\n",
    "    if df_monthly_miss.shape[0] > 0:\n",
    "        print(f'Filling missing with {method}')\n",
    "        df_monthly_miss.drop(['price'], axis=1, inplace=True)\n",
    "        mean_price, merge_columns = get_mean_price(df_daily_train, method)\n",
    "        # fill the missing\n",
    "        df_monthly_miss_filled = pd.merge(\n",
    "            df_monthly_miss, \n",
    "            mean_price,\n",
    "            on=merge_columns,\n",
    "            how='left')\n",
    "        df_monthly = pd.concat([df_monthly_full, df_monthly_miss_filled], ignore_index=True)\n",
    "        df_monthly = df_monthly.sort_values(by = ['monthly_period', 'shop_id', 'item_id'])\n",
    "        count_missing_price = df_monthly.loc[df_monthly['price'].isna(), :].shape[0]\n",
    "        print(f'after the operation, count of rows with missing price: {count_missing_price}')\n",
    "        if count_missing_price > 0: \n",
    "            if method == 'mean shop-item-specific price':\n",
    "                df_monthly = add_avg_shopitem_price_to_df(df_monthly, df_daily_train, 'mean item-specific price')\n",
    "            elif method == 'mean item-specific price':\n",
    "                df_monthly = add_avg_shopitem_price_to_df(df_monthly, df_daily_train, 'mean category-specific price')\n",
    "            elif method == 'mean category-specific price':\n",
    "                print(f'Filling missing with global average price')\n",
    "                global_avg_price = df_daily_train[['price']].mean().values[0]\n",
    "                df_monthly.loc[df_monthly['price'].isna(), 'price'] = float(global_avg_price)\n",
    "            else:\n",
    "                raise ValueError(f'Uknown method: {method}')\n",
    "    else:\n",
    "        df_monthly = df_monthly_full\n",
    "    return df_monthly\n",
    "\n",
    "# Year and month can help capturing the trend and the seasonality, respectively\n",
    "def add_time_features(df_monthly):\n",
    "    df_monthly['year'] = df_monthly['monthly_period'].dt.year\n",
    "    df_monthly['month'] = df_monthly['monthly_period'].dt.month\n",
    "    return df_monthly\n",
    "\n",
    "def add_lag_ma_features(\n",
    "        df_monthly\n",
    "        lags_to_include=3,\n",
    "        lag_features=['price', 'amount_item', 'amount_cat'],\n",
    "        mas_to_include=[2],\n",
    "        ma_features=['price_l1', 'amount_item_l1', 'amount_cat_l1']\n",
    "        ):\n",
    "    # df_monthly = add_feature_lags(df_monthly, 'price', 3)\n",
    "    # df_monthly = add_feature_lags(df_monthly, 'amount_item', 3)\n",
    "    # df_monthly = add_feature_lags(df_monthly, 'amount_cat', 3)\n",
    "    for feature in lag_features:\n",
    "        df_monthly = add_feature_lags(\n",
    "            df_monthly,\n",
    "            feature,\n",
    "            lags_to_include)\n",
    "    # df_monthly = add_feature_moving_averages(df_monthly, 'price_l1', [2])\n",
    "    # df_monthly = add_feature_moving_averages(df_monthly, 'amount_item_l1', [2])\n",
    "    # df_monthly = add_feature_moving_averages(df_monthly, 'amount_cat_l1', [2])\n",
    "    for feature in ma_features:\n",
    "        df_monthly = add_feature_moving_averages(\n",
    "            df_monthly,\n",
    "            feature,\n",
    "            mas_to_include)\n",
    "    return df_monthly\n",
    "\n",
    "def add_feature_lags(df, column, lagcount):\n",
    "    for lag in range(1, lagcount+1):\n",
    "        new_column_name = column + '_l' + str(lag)\n",
    "        df[new_column_name] = df.groupby(['shop_id', 'item_id'])[column].shift(lag)\n",
    "    return df\n",
    "\n",
    "def add_feature_moving_averages(df, column, windows):\n",
    "    for window in windows:\n",
    "        new_column_name = column + '_ma' + str(window)\n",
    "        df[new_column_name] = df.groupby(['shop_id', 'item_id'])[column].transform(lambda x: x.rolling(window=window).mean())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare monthly training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data needed for both train and val\n",
    "df_shops= treepredictor.rawdata.shop_list\n",
    "df_items = treepredictor.rawdata.item_list[['item_id', 'item_category_id']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep_pipeline(\n",
    "        df_daily,\n",
    "        df_shops,\n",
    "        df_items,\n",
    "        splitname,\n",
    "        refresh):\n",
    "    fn_ts = config[f'fn_{splitname}_ts']\n",
    "    if os.path_exists(fn_ts) and not refresh:\n",
    "        df_ts = pd.read_parquet(fn_ts)\n",
    "    else:\n",
    "        fn_base = config[f'fn_{splitname}_base']\n",
    "        if os.path.exists(fn_base) and not refresh:\n",
    "            df_base = pd.read_parquet(fn_base)\n",
    "        else:\n",
    "            df_base = prep_monthly_data(df_daily, df_shops, df_items)\n",
    "            df_base.to_parquet(fn_base)\n",
    "        df_ts = add_lag_ma_features(df_base)\n",
    "        df_ts.to_parquet(fn_ts)\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the operation, count of rows with missing categories: 0\n",
      "1369923 and 34545477 rows with filled and missing prices, respectively.\n",
      "Filling missing with mean shop-item-specific price\n",
      "after the operation, count of rows with missing price: 25607232\n",
      "10308168 and 25607232 rows with filled and missing prices, respectively.\n",
      "Filling missing with mean item-specific price\n",
      "after the operation, count of rows with missing price: 4179600\n",
      "31735800 and 4179600 rows with filled and missing prices, respectively.\n",
      "Filling missing with mean category-specific price\n",
      "after the operation, count of rows with missing price: 71280\n",
      "Filling missing with global average price\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35915400 entries, 0 to 35915399\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count     Dtype    \n",
      "---  ------            --------------     -----    \n",
      " 0   shop_id           35915400 non-null  int32    \n",
      " 1   item_id           35915400 non-null  int32    \n",
      " 2   monthly_period    35915400 non-null  period[M]\n",
      " 3   item_category_id  35915400 non-null  float64  \n",
      " 4   price             35915400 non-null  float32  \n",
      " 5   amount_item       35915400 non-null  float32  \n",
      " 6   amount_cat        35915400 non-null  float32  \n",
      "dtypes: float32(3), float64(1), int32(2), period[M](1)\n",
      "memory usage: 1.2 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35915400 entries, 0 to 35915399\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Dtype    \n",
      "---  ------            -----    \n",
      " 0   shop_id           int32    \n",
      " 1   item_id           int32    \n",
      " 2   monthly_period    period[M]\n",
      " 3   item_category_id  float64  \n",
      " 4   price             float32  \n",
      " 5   amount_item       float32  \n",
      " 6   amount_cat        float32  \n",
      "dtypes: float32(3), float64(1), int32(2), period[M](1)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "columns_needed = ['monthly_period', 'shop_id', 'item_id', 'item_category_id', 'amount', 'price']\n",
    "df_daily_train = treepredictor.df_daily_train[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_train = data_prep_pipeline(\n",
    "    df_daily_train,\n",
    "    df_shops,\n",
    "    df_items,\n",
    "    'train',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "train_y = df_train['amount_item']\n",
    "df_train.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "train_X = df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_val = treepredictor.df_daily_val[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_val = data_prep_pipeline(\n",
    "    df_daily_val,\n",
    "    df_shops,\n",
    "    df_items,\n",
    "    'val',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "val_y = df_val['amount_item']\n",
    "df_train.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "val_X = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc['2013-01', :].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc['2013-02', :].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc['2013-03', :].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.loc['2013-04', :].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
