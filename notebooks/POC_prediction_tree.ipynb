{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Pipeline: Tree-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import pandas as pd\n",
    "import parquet\n",
    "\n",
    "from tree_predictor import TreePredictor\n",
    "from utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Utils.read_config_for_env(config_path='../config/config.yml')\n",
    "treepredictor = TreePredictor(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare monthly training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: when ready, move this to tree_predictor\n",
    "def data_prep_pipeline(\n",
    "        df_daily,\n",
    "        splitname,\n",
    "        refresh):\n",
    "    \n",
    "    # get base monthly data\n",
    "    df_base = treepredictor.data.get_monthly_data(df_daily, splitname, refresh)\n",
    "\n",
    "    # get monthly data with lag and ma features\n",
    "    df_ts= treepredictor.data.get_ts_data(df_base, splitname, refresh, treepredictor.num_lag_mon)\n",
    "    \n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_needed = ['monthly_period', 'shop_id', 'item_id', 'item_category_id', 'amount', 'price']\n",
    "df_daily_train = treepredictor.df_daily_train[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_train = data_prep_pipeline(\n",
    "    df_daily_train,\n",
    "    'train',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "y_train = df_train['amount_item']\n",
    "df_train.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_val = treepredictor.df_daily_val[columns_needed].copy()\n",
    "# df_daily_train.info()\n",
    "df_val = data_prep_pipeline(\n",
    "    df_daily_val,\n",
    "    'val',\n",
    "    refresh=False)\n",
    "\n",
    "# create X and y\n",
    "y_val = df_val['amount_item']\n",
    "df_val.drop(columns=['price', 'amount_item', 'amount_cat'], axis=1, inplace=True)\n",
    "X_val= df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# from lightgbm import LGBMRegressor \n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.metrics import mean_squared_error as mse \n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LightGBM dataset for training with features X_train and labels Y_train \n",
    "train_data = lgb.Dataset(X_train, label=y_train) \n",
    "# Create a LightGBM dataset for testing with features X_val and labels Y_val, \n",
    "# and specify the reference dataset as train_data for consistent evaluation \n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data) \n",
    "# Define a dictionary of parameters for configuring the LightGBM regression model. \n",
    "params = { \n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "}\n",
    "callback_early_stopping = lgb.early_stopping(5)\n",
    "num_round = 100\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_round,\n",
    "    valid_sets=[val_data],\n",
    "    callbacks=[callback_early_stopping, lgb.log_evaluation()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training and validation data. \n",
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)\n",
    "\n",
    "# Calculate and print the Root Mean Squared Error (RMSE) for training and validation predictions. \n",
    "print(\"Training RMSE: \", np.sqrt(mse(y_train, pred_train)))\n",
    "print(\"Validation RMSE: \", np.sqrt(mse(y_val, pred_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
